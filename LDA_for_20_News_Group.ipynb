{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA for 20 News Group.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm_Qbq5jHrzc",
        "colab_type": "text"
      },
      "source": [
        "# **Latent Dirichlet Allocation(LDA) for 20 News Group**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgzSzZtIINbX",
        "colab_type": "text"
      },
      "source": [
        "**Topic:** Data Scientist Intern at RBC<br>\n",
        "**Name:** Xu(Shawn) Zhang<br>\n",
        "**Date:** May 11, 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBIJaBPOIEsA",
        "colab_type": "code",
        "outputId": "907c5291-d741-42ed-a881-6c470ec96aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#@title Import { display-mode: \"form\" }\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "random.seed(2019)\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unxVb8DAIYbY",
        "colab_type": "text"
      },
      "source": [
        "### **Load the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq2qeRbJb3DV",
        "colab_type": "text"
      },
      "source": [
        "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.<br>\n",
        "\n",
        "**sklearn.datasets.fetch_20newsgroups**, returns a list of the raw texts that can be fed to text feature extractors with custom parameters so as to extract feature vectors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qYLchVMsoqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzgln4LgIoSw",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocess the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkIleDiad3Is",
        "colab_type": "text"
      },
      "source": [
        "**1. Stemming**\n",
        "\n",
        "stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root formâ€”generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root.<br>\n",
        "\n",
        "The three major stemming algorithms in use today are Porter, Snowball(Porter2), and Lancaster (Paice-Husk). Where Porter is the most commonly used stemmer and one of the most gentle stemmers; Snowball is regarded as an improvement over porter and it has slightly faster computation time than porter, with a fairly large community around it. Lancaster is the fastest algorithm here, and will reduce your working set of words hugely, so it is a very aggressive stemming algorithm, sometimes to a fault.\n",
        "\n",
        "**2. lemmatization**\n",
        "\n",
        "In many languages, words appear in several inflected forms. For example, in English, the verb 'to walk' may appear as 'walk', 'walked', 'walks' or 'walking'. The base form, 'walk', that one might look up in a dictionary, is called the lemma for the word. In computational linguistics, lemmatisation is the algorithmic process of determining the lemma of a word based on its intended meaning.<br>\n",
        "\n",
        "Wordnet is an large, freely and publicly available lexical database for the English language aiming to establish structured semantic relationships between words. It offers lemmatization capabilities as well and is one of the earliest and most commonly used lemmatizers.\n",
        "\n",
        "**3. Tokenization**\n",
        "\n",
        "Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph.\n",
        "\n",
        "In gensim, we can perform tokenization using **gensim.utils.simple_preprocess(doc, deacc=False, min_len=2, max_len=15)**:\n",
        "- **doc:** the document to be tokenized\n",
        "- **deacc:** de-accents\n",
        "- **min_len:** minimum length of token\n",
        "- **max_len:** maximum length of token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQmsHj8Dsu0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word stemming and lemmatization\n",
        "def lemmatize_stemming(text):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Text preprocessing\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Get preprocessed dataset\n",
        "processed_docs = []\n",
        "\n",
        "for doc in newsgroups_train.data:\n",
        "    processed_docs.append(preprocess(doc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uk_1p8yb-XO",
        "colab_type": "text"
      },
      "source": [
        "### **Create Bag of Words(BOW) Representation of the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eKrb2xZmL7g",
        "colab_type": "text"
      },
      "source": [
        "**Class gensim.corpora.Dictionary(documents=None, prune_at=2000000)**\n",
        "\n",
        "Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
        "\n",
        "**Methods:**<br>\n",
        "**1. Dictionary.filter_extremes(no_below=10, no_above=0.7, keep_n=100000)**\n",
        "- **no_below=10** means word appears less than 10 documents\n",
        "- **no_above=0.7** means word appears more than 70% documents\n",
        "- **keep_n=100000** means keep only the first 100000 most frequent tokens\n",
        "\n",
        "**2. Dictionary.doc2bow(document, allow_update=False, return_missing=False)**\n",
        "- **document:** document to be converted into BOW\n",
        "- **allow_update:** if allow_update is set, update dictionary and document frequencies in the process.\n",
        "- **return_missing:** if true, also return words not in dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqMdEA_qs0AW",
        "colab_type": "code",
        "outputId": "f72c6d2f-3b27-46fc-e9bd-a0aa0d667d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "# Create word dictionary / word2id\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "\n",
        "# Filter out low frequency and high frequency words\n",
        "dictionary.filter_extremes(no_below=10, no_above=0.7, keep_n=100000)\n",
        "\n",
        "# Create Bag of Words(BOW) representation of dataset\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "# Preview BOW for our sample preprocessed document\n",
        "document_num = 1\n",
        "bow_doc_x = bow_corpus[document_num]\n",
        "\n",
        "for i in range(10):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0],\n",
        "                                                     dictionary[bow_doc_x[i][0]],\n",
        "                                                     bow_doc_x[i][1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 11 (\"host\") appears 1 time.\n",
            "Word 20 (\"nntp\") appears 1 time.\n",
            "Word 22 (\"post\") appears 1 time.\n",
            "Word 29 (\"thank\") appears 1 time.\n",
            "Word 31 (\"univers\") appears 1 time.\n",
            "Word 34 (\"acceler\") appears 1 time.\n",
            "Word 35 (\"adapt\") appears 1 time.\n",
            "Word 36 (\"answer\") appears 1 time.\n",
            "Word 37 (\"articl\") appears 1 time.\n",
            "Word 38 (\"attain\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsjBmZWihe1N",
        "colab_type": "text"
      },
      "source": [
        "### **Build and Train LDA Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7wOF_AqKG3",
        "colab_type": "text"
      },
      "source": [
        "We can build LDA model using **gensim.models.LdaMulticore** API, it using all CPU cores to parallelize and speed up model training.\n",
        "- **corpus:** the input corpus for LDA model\n",
        "- **id2word:** mapping from word IDs to words. \n",
        "- **num_topics:** the number of topics, to compare LDA and ETM, set to the same as num_topics in ETM\n",
        "- **chunksize:** number of documents to load into memory at a time and process E step of EM, we can save some memory using the smaller chunksize, but will be doing multiple loading/processing steps prior to moving onto the M step, in practice we can set 100 to consider speed and memory.\n",
        "- **passes:** number of passes through the corpus during training, in practice set to 10 to get fairly good results.\n",
        "- **iterations:** number of iterations of EM algorithm, default value is 50, to compare with ETM(which set epochs=1000, where epochs stands for the number times that the learning algorithm will work through the entire training dataset), we set iterations=1000. But notics that different model may has it's own optimal epochs.\n",
        "\n",
        "Below are some of examples to show the effect of chunksize and passes: <br>\n",
        "chunksize = 100k, corpus = 1M docs, passes =1 : 10 updates total<br>\n",
        "chunksize = 100k, corpus = 1M docs, passes =2 : 20 updates total<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCS711F6Yje7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and train LDA model for 20 topics\n",
        "lda_model_20 = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
        "                                          id2word=dictionary,\n",
        "                                          num_topics=20, \n",
        "                                          random_state=100,\n",
        "                                          chunksize=100,\n",
        "                                          iterations=50,\n",
        "                                          passes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDd8_y6fs5jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and train LDA model for 50 topics\n",
        "lda_model_50 = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
        "                                          id2word=dictionary,\n",
        "                                          num_topics=50, \n",
        "                                          random_state=100,\n",
        "                                          chunksize=100,\n",
        "                                          iterations=50,\n",
        "                                          passes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRUFnQR0FR90",
        "colab_type": "code",
        "outputId": "89558f88-3a33-4d5c-fc9d-fbcdfd12e014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Build and train LDA model for 100 topics\n",
        "lda_model_100 = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=100, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           iterations=50,\n",
        "                                           passes=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15taefviFUWW",
        "colab_type": "code",
        "outputId": "4ab8b728-561a-47bf-ea65-825fb407a183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Build and train LDA model for 300 topics\n",
        "lda_model_300 = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=300, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           iterations=50,\n",
        "                                           passes=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzn6UZRohuem",
        "colab_type": "text"
      },
      "source": [
        "### **Visualize Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00TXYRMTYolj",
        "colab_type": "text"
      },
      "source": [
        "#### **1. For 20 topics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVWrbyB9Yupj",
        "colab_type": "text"
      },
      "source": [
        "For each topic, we will explore the words occuring in that topic and its relative weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZSWwZ7wYrzV",
        "colab_type": "code",
        "outputId": "3e364fe3-42e1-43c7-e019-6d6511d00022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "# Visualize the results\n",
        "topics_20 = []\n",
        "for idx, topic in lda_model_20.print_topics(num_topics=10, num_words=10):\n",
        "    topics_20.append(topic)\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 16 \n",
            "Words: 0.024*\"sale\" + 0.020*\"washington\" + 0.013*\"price\" + 0.012*\"sell\" + 0.010*\"offer\" + 0.010*\"leagu\" + 0.009*\"year\" + 0.009*\"host\" + 0.009*\"nntp\" + 0.009*\"univers\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.030*\"christian\" + 0.016*\"believ\" + 0.016*\"jesus\" + 0.016*\"exist\" + 0.015*\"faith\" + 0.013*\"write\" + 0.012*\"bibl\" + 0.012*\"evid\" + 0.011*\"religion\" + 0.010*\"atheist\"\n",
            "\n",
            "\n",
            "Topic: 11 \n",
            "Words: 0.020*\"state\" + 0.014*\"nation\" + 0.013*\"presid\" + 0.011*\"american\" + 0.010*\"year\" + 0.009*\"public\" + 0.009*\"announc\" + 0.009*\"clinton\" + 0.008*\"group\" + 0.008*\"issu\"\n",
            "\n",
            "\n",
            "Topic: 19 \n",
            "Words: 0.024*\"write\" + 0.019*\"articl\" + 0.013*\"bike\" + 0.013*\"uiuc\" + 0.011*\"drive\" + 0.010*\"engin\" + 0.010*\"colorado\" + 0.009*\"car\" + 0.009*\"like\" + 0.008*\"umich\"\n",
            "\n",
            "\n",
            "Topic: 18 \n",
            "Words: 0.045*\"space\" + 0.027*\"nasa\" + 0.018*\"research\" + 0.016*\"scienc\" + 0.015*\"orbit\" + 0.013*\"sphere\" + 0.013*\"earth\" + 0.011*\"launch\" + 0.011*\"center\" + 0.009*\"moon\"\n",
            "\n",
            "\n",
            "Topic: 0 \n",
            "Words: 0.020*\"peopl\" + 0.013*\"like\" + 0.013*\"think\" + 0.012*\"reason\" + 0.010*\"know\" + 0.010*\"right\" + 0.009*\"thing\" + 0.009*\"point\" + 0.008*\"write\" + 0.007*\"time\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.039*\"post\" + 0.036*\"host\" + 0.035*\"nntp\" + 0.026*\"write\" + 0.025*\"articl\" + 0.024*\"slave\" + 0.024*\"freenet\" + 0.022*\"andrew\" + 0.020*\"caltech\" + 0.017*\"keith\"\n",
            "\n",
            "\n",
            "Topic: 14 \n",
            "Words: 0.027*\"file\" + 0.022*\"program\" + 0.020*\"window\" + 0.012*\"entri\" + 0.011*\"sourc\" + 0.010*\"imag\" + 0.010*\"applic\" + 0.009*\"avail\" + 0.009*\"includ\" + 0.008*\"code\"\n",
            "\n",
            "\n",
            "Topic: 8 \n",
            "Words: 0.034*\"write\" + 0.033*\"articl\" + 0.017*\"michael\" + 0.014*\"food\" + 0.014*\"homosexu\" + 0.012*\"alaska\" + 0.012*\"austin\" + 0.012*\"univers\" + 0.012*\"jeff\" + 0.011*\"utexa\"\n",
            "\n",
            "\n",
            "Topic: 9 \n",
            "Words: 0.020*\"access\" + 0.019*\"write\" + 0.017*\"post\" + 0.015*\"columbia\" + 0.014*\"host\" + 0.014*\"nntp\" + 0.012*\"univers\" + 0.012*\"digex\" + 0.011*\"peter\" + 0.010*\"jason\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Pn_1ijQtNk",
        "colab_type": "text"
      },
      "source": [
        "#### **2. For 50 topics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-j1MZ4HY0Tr",
        "colab_type": "text"
      },
      "source": [
        "For each topic, we will explore the words occuring in that topic and its relative weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54XWcmUSs-zO",
        "colab_type": "code",
        "outputId": "309d3772-c534-4029-a236-b321f242a5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "# Visualize the results\n",
        "topics_50 = []\n",
        "for idx, topic in lda_model_50.print_topics(num_topics=10, num_words=10):\n",
        "    topics_50.append(topic)\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 29 \n",
            "Words: 0.105*\"netcom\" + 0.033*\"write\" + 0.032*\"homosexu\" + 0.028*\"articl\" + 0.026*\"cool\" + 0.024*\"water\" + 0.020*\"guest\" + 0.019*\"heat\" + 0.019*\"communic\" + 0.019*\"cycl\"\n",
            "\n",
            "\n",
            "Topic: 40 \n",
            "Words: 0.029*\"go\" + 0.027*\"think\" + 0.026*\"say\" + 0.025*\"know\" + 0.022*\"peopl\" + 0.022*\"come\" + 0.019*\"time\" + 0.018*\"like\" + 0.016*\"tell\" + 0.012*\"happen\"\n",
            "\n",
            "\n",
            "Topic: 49 \n",
            "Words: 0.022*\"weapon\" + 0.021*\"gun\" + 0.020*\"access\" + 0.018*\"right\" + 0.017*\"crime\" + 0.016*\"state\" + 0.015*\"firearm\" + 0.015*\"arm\" + 0.014*\"columbia\" + 0.013*\"amend\"\n",
            "\n",
            "\n",
            "Topic: 22 \n",
            "Words: 0.066*\"technolog\" + 0.064*\"caltech\" + 0.061*\"institut\" + 0.055*\"keith\" + 0.048*\"california\" + 0.037*\"pasadena\" + 0.032*\"keyboard\" + 0.026*\"motto\" + 0.025*\"post\" + 0.024*\"host\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.036*\"like\" + 0.030*\"problem\" + 0.029*\"good\" + 0.025*\"time\" + 0.022*\"thing\" + 0.018*\"help\" + 0.017*\"know\" + 0.016*\"work\" + 0.014*\"need\" + 0.013*\"think\"\n",
            "\n",
            "\n",
            "Topic: 35 \n",
            "Words: 0.051*\"michael\" + 0.049*\"lebanes\" + 0.036*\"articl\" + 0.033*\"write\" + 0.027*\"henri\" + 0.024*\"alaska\" + 0.023*\"toronto\" + 0.023*\"west\" + 0.021*\"cambridg\" + 0.019*\"adam\"\n",
            "\n",
            "\n",
            "Topic: 19 \n",
            "Words: 0.064*\"bike\" + 0.059*\"colorado\" + 0.034*\"rider\" + 0.026*\"ride\" + 0.025*\"spot\" + 0.019*\"owner\" + 0.018*\"wave\" + 0.018*\"spring\" + 0.016*\"seat\" + 0.016*\"club\"\n",
            "\n",
            "\n",
            "Topic: 46 \n",
            "Words: 0.029*\"gari\" + 0.025*\"trade\" + 0.022*\"buffalo\" + 0.019*\"divis\" + 0.018*\"pen\" + 0.016*\"greg\" + 0.015*\"stanley\" + 0.015*\"pittsburgh\" + 0.015*\"play\" + 0.014*\"leaf\"\n",
            "\n",
            "\n",
            "Topic: 9 \n",
            "Words: 0.050*\"indiana\" + 0.043*\"joseph\" + 0.036*\"brown\" + 0.035*\"dale\" + 0.032*\"digit\" + 0.032*\"lanc\" + 0.029*\"signal\" + 0.025*\"blue\" + 0.025*\"level\" + 0.024*\"electron\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.054*\"articl\" + 0.052*\"write\" + 0.046*\"stanford\" + 0.040*\"brian\" + 0.035*\"king\" + 0.034*\"jam\" + 0.033*\"univers\" + 0.031*\"uchicago\" + 0.020*\"rutger\" + 0.019*\"midway\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8AuPmY7dQoh",
        "colab_type": "text"
      },
      "source": [
        "#### **2. For 100 topics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNXSwmfydSpY",
        "colab_type": "text"
      },
      "source": [
        "For each topic, we will explore the words occuring in that topic and its relative weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWJjQPJ-dWG5",
        "colab_type": "code",
        "outputId": "86b42443-23c9-4c7d-b9e1-f7da668d0869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "# Visualize the results\n",
        "topics_100 = []\n",
        "for idx, topic in lda_model_100.print_topics(num_topics=10, num_words=10):\n",
        "    topics_100.append(topic)\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 57 \n",
            "Words: 0.122*\"colorado\" + 0.059*\"buffalo\" + 0.055*\"vote\" + 0.042*\"state\" + 0.039*\"cursor\" + 0.036*\"thier\" + 0.033*\"boulder\" + 0.032*\"prize\" + 0.031*\"revers\" + 0.028*\"remind\"\n",
            "\n",
            "\n",
            "Topic: 25 \n",
            "Words: 0.049*\"sourc\" + 0.041*\"entri\" + 0.029*\"section\" + 0.028*\"code\" + 0.028*\"page\" + 0.026*\"number\" + 0.025*\"contain\" + 0.025*\"follow\" + 0.022*\"includ\" + 0.020*\"inform\"\n",
            "\n",
            "\n",
            "Topic: 41 \n",
            "Words: 0.058*\"time\" + 0.037*\"advic\" + 0.036*\"week\" + 0.036*\"hour\" + 0.032*\"father\" + 0.029*\"long\" + 0.028*\"doctor\" + 0.027*\"wait\" + 0.026*\"acn\" + 0.025*\"island\"\n",
            "\n",
            "\n",
            "Topic: 93 \n",
            "Words: 0.210*\"space\" + 0.139*\"nasa\" + 0.067*\"orbit\" + 0.051*\"launch\" + 0.039*\"mission\" + 0.034*\"shuttl\" + 0.032*\"satellit\" + 0.032*\"station\" + 0.030*\"flight\" + 0.023*\"astro\"\n",
            "\n",
            "\n",
            "Topic: 60 \n",
            "Words: 0.101*\"bank\" + 0.098*\"pitt\" + 0.079*\"univ\" + 0.059*\"gordon\" + 0.055*\"soon\" + 0.039*\"widget\" + 0.037*\"surveil\" + 0.037*\"pittsburgh\" + 0.036*\"articl\" + 0.033*\"repli\"\n",
            "\n",
            "\n",
            "Topic: 42 \n",
            "Words: 0.118*\"group\" + 0.058*\"umich\" + 0.052*\"newsgroup\" + 0.040*\"engin\" + 0.035*\"internet\" + 0.028*\"planet\" + 0.027*\"discuss\" + 0.026*\"compos\" + 0.023*\"advanc\" + 0.019*\"journal\"\n",
            "\n",
            "\n",
            "Topic: 84 \n",
            "Words: 0.095*\"govern\" + 0.093*\"nation\" + 0.089*\"american\" + 0.073*\"white\" + 0.067*\"hous\" + 0.047*\"privat\" + 0.045*\"countri\" + 0.040*\"press\" + 0.026*\"econom\" + 0.023*\"care\"\n",
            "\n",
            "\n",
            "Topic: 69 \n",
            "Words: 0.084*\"ethernet\" + 0.065*\"hole\" + 0.059*\"georgia\" + 0.052*\"gatech\" + 0.049*\"marc\" + 0.045*\"tech\" + 0.038*\"misc\" + 0.036*\"prism\" + 0.030*\"institut\" + 0.028*\"boot\"\n",
            "\n",
            "\n",
            "Topic: 30 \n",
            "Words: 0.179*\"faith\" + 0.111*\"human\" + 0.101*\"moral\" + 0.077*\"word\" + 0.074*\"anim\" + 0.060*\"revel\" + 0.059*\"save\" + 0.047*\"explain\" + 0.029*\"defin\" + 0.020*\"fish\"\n",
            "\n",
            "\n",
            "Topic: 63 \n",
            "Words: 0.174*\"steve\" + 0.114*\"valu\" + 0.113*\"steven\" + 0.093*\"frank\" + 0.048*\"period\" + 0.048*\"stephen\" + 0.038*\"loui\" + 0.035*\"ford\" + 0.025*\"man\" + 0.023*\"associ\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VJOHlNwdb75",
        "colab_type": "text"
      },
      "source": [
        "#### **3. For 300 topics**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3gBUzsdfHt",
        "colab_type": "text"
      },
      "source": [
        "For each topic, we will explore the words occuring in that topic and its relative weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G18UawxndhnK",
        "colab_type": "code",
        "outputId": "6203a645-c749-4f00-9df5-383899f4aff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "# Visualize the results\n",
        "topics_300 = []\n",
        "for idx, topic in lda_model_300.print_topics(num_topics=10, num_words=10):\n",
        "    topics_300.append(topic)\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 241 \n",
            "Words: 0.226*\"ignor\" + 0.134*\"chanc\" + 0.078*\"upenn\" + 0.065*\"visibl\" + 0.062*\"maintain\" + 0.050*\"quiet\" + 0.047*\"solv\" + 0.046*\"threaten\" + 0.046*\"blame\" + 0.040*\"threat\"\n",
            "\n",
            "\n",
            "Topic: 175 \n",
            "Words: 0.000*\"jolla\" + 0.000*\"pythagorean\" + 0.000*\"ggrrrrrr\" + 0.000*\"marcus\" + 0.000*\"mcguir\" + 0.000*\"piss\" + 0.000*\"jay\" + 0.000*\"unto\" + 0.000*\"padr\" + 0.000*\"danc\"\n",
            "\n",
            "\n",
            "Topic: 120 \n",
            "Words: 0.311*\"say\" + 0.047*\"know\" + 0.046*\"fact\" + 0.044*\"come\" + 0.037*\"convinc\" + 0.034*\"refer\" + 0.027*\"like\" + 0.026*\"tell\" + 0.026*\"reveal\" + 0.025*\"scriptur\"\n",
            "\n",
            "\n",
            "Topic: 283 \n",
            "Words: 0.171*\"attack\" + 0.132*\"soldier\" + 0.073*\"civilian\" + 0.061*\"brad\" + 0.060*\"kill\" + 0.058*\"blood\" + 0.047*\"effort\" + 0.044*\"territori\" + 0.044*\"border\" + 0.040*\"northern\"\n",
            "\n",
            "\n",
            "Topic: 254 \n",
            "Words: 0.174*\"jam\" + 0.125*\"texa\" + 0.113*\"austin\" + 0.103*\"purdu\" + 0.095*\"utexa\" + 0.080*\"univers\" + 0.078*\"lanc\" + 0.050*\"roman\" + 0.035*\"cult\" + 0.031*\"timothi\"\n",
            "\n",
            "\n",
            "Topic: 214 \n",
            "Words: 0.381*\"opinion\" + 0.118*\"express\" + 0.092*\"dead\" + 0.069*\"disclaim\" + 0.065*\"planet\" + 0.060*\"compos\" + 0.052*\"rock\" + 0.048*\"journal\" + 0.040*\"abort\" + 0.029*\"presenc\"\n",
            "\n",
            "\n",
            "Topic: 86 \n",
            "Words: 0.180*\"imagin\" + 0.171*\"hole\" + 0.087*\"toni\" + 0.076*\"accus\" + 0.065*\"engr\" + 0.057*\"render\" + 0.047*\"aluminum\" + 0.041*\"assault\" + 0.037*\"blast\" + 0.037*\"louisiana\"\n",
            "\n",
            "\n",
            "Topic: 63 \n",
            "Words: 0.220*\"camp\" + 0.192*\"water\" + 0.152*\"slight\" + 0.125*\"movement\" + 0.103*\"youth\" + 0.062*\"england\" + 0.037*\"coventri\" + 0.037*\"ahem\" + 0.021*\"pour\" + 0.016*\"boil\"\n",
            "\n",
            "\n",
            "Topic: 260 \n",
            "Words: 0.178*\"proper\" + 0.171*\"usenet\" + 0.146*\"rise\" + 0.105*\"channel\" + 0.080*\"indic\" + 0.080*\"fnal\" + 0.051*\"confirm\" + 0.043*\"anthoni\" + 0.028*\"gate\" + 0.027*\"hamilton\"\n",
            "\n",
            "\n",
            "Topic: 29 \n",
            "Words: 0.182*\"koresh\" + 0.173*\"tech\" + 0.160*\"recal\" + 0.151*\"investig\" + 0.111*\"batf\" + 0.071*\"justif\" + 0.054*\"temperatur\" + 0.035*\"believ\" + 0.033*\"raid\" + 0.007*\"surpris\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqR20CcQh1WX",
        "colab_type": "text"
      },
      "source": [
        "### **Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbJ9yU0Lh6ww",
        "colab_type": "text"
      },
      "source": [
        "**1. Calculate Topic Coherence(TC)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ASiFoEBjM8q",
        "colab_type": "text"
      },
      "source": [
        "Gensim provides Topic Coherence(TC) API to calculate TC, the details of different TC calculation methods can be found here:https://palmetto.demos.dice-research.org/<br>\n",
        "\n",
        "The TC measurement mentioned in the ETM paper: https://arxiv.org/pdf/1907.04907.pdf is NPMI, we use this measurement to calculate TC of LDA is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYcd2XHDY6Gw",
        "colab_type": "code",
        "outputId": "a74b41c6-43e4-4f8f-b000-42f6fbfa8d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Get Topic Coherence(TC) for 20 topics\n",
        "coherence_model_lda_20 = CoherenceModel(model=lda_model_20, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
        "coherence_lda_20 = coherence_model_lda_20.get_coherence()\n",
        "\n",
        "print(\"The Topic Coherence(TC) of LDA model for 20 topics calculated using API is:\", coherence_lda_20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) of LDA model for 20 topics calculated using API is: 0.00185423528902863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwYGCDb58OmG",
        "colab_type": "code",
        "outputId": "520f29fa-1cc7-429d-bc0c-6dfc9254dfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Get Topic Coherence(TC) for 50 topics\n",
        "coherence_model_lda_50 = CoherenceModel(model=lda_model_50, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
        "coherence_lda_50 = coherence_model_lda_50.get_coherence()\n",
        "\n",
        "print(\"The Topic Coherence(TC) of LDA model for 50 topics calculated using API is:\", coherence_lda_50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) of LDA model for 50 topics calculated using API is: -0.06824679916267129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W6SW2J8YaD",
        "colab_type": "code",
        "outputId": "b213a9e4-fecc-42f5-b299-074dc2aaa765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Get Topic Coherence(TC) for 100 topics\n",
        "coherence_model_lda_100 = CoherenceModel(model=lda_model_100, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
        "coherence_lda_100 = coherence_model_lda_100.get_coherence()\n",
        "\n",
        "print(\"The Topic Coherence(TC) of LDA model for 100 topics calculated using API is:\", coherence_lda_100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) of LDA model for 100 topics calculated using API is: -0.11313425676892294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyT9TtqBbbc",
        "colab_type": "code",
        "outputId": "112a2126-3584-48b7-d3e9-e08ca7ac705a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Get Topic Coherence(TC) for 100 topics\n",
        "coherence_model_lda_300 = CoherenceModel(model=lda_model_300, texts=processed_docs, dictionary=dictionary, coherence='c_npmi')\n",
        "coherence_lda_300 = coherence_model_lda_300.get_coherence()\n",
        "\n",
        "print(\"The Topic Coherence(TC) of LDA model for 300 topics calculated using API is:\", coherence_lda_300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) of LDA model for 300 topics calculated using API is: -0.2118525558847258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL9Q1BsMY7sX",
        "colab_type": "text"
      },
      "source": [
        "To compare with ETM paper, I implememnt TC from scratch as the same way as the code provided by ETM paper, and the implementation details and corresponding result is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyuXdyRmXVsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "# Filter out punctuations\n",
        "def contains_punctuation(w):\n",
        "    return any(char in string.punctuation for char in w)\n",
        "\n",
        "# Filter out numeric values\n",
        "def contains_numeric(w):\n",
        "    return any(char.isdigit() for char in w)\n",
        "\n",
        "# Document frequency\n",
        "def D_w(word, corpus):\n",
        "  D_w = 0\n",
        "  for i in range(len(corpus)):\n",
        "    if word in corpus[i]:\n",
        "      D_w += 1\n",
        "  return D_w\n",
        "\n",
        "# Get Topic Coherence(TC)\n",
        "def topic_coherence(corpus, topics):\n",
        "  \n",
        "  # Select top-10 most likely words in each topic\n",
        "  words = [None] * len(topics)\n",
        "  for i in range(len(topics)):\n",
        "    topic = topics[i]\n",
        "    topic = [w.lower() for w in topic if not contains_punctuation(w)] \n",
        "    topic = [w for w in topic if not contains_numeric(w)]\n",
        "    topic = \"\".join(topic)\n",
        "    topic = topic.split(sep=' ')\n",
        "    topic = [w for w in topic if w != '']\n",
        "    words[i] = topic[0:11]\n",
        "  \n",
        "  # Calculate topic coherence\n",
        "  D = len(corpus)\n",
        "  TC = []\n",
        "  for k in range(len(words)):\n",
        "    TC_k = 0\n",
        "    counter = 0\n",
        "    word_k = words[k]\n",
        "    \n",
        "    for i in range(10):\n",
        "      w_i = word_k[i]\n",
        "      tmp = 0\n",
        "\n",
        "      for j in range(i+1, 10):\n",
        "        w_j = word_k[j]\n",
        "        D_wi = D_w(w_i, corpus)\n",
        "        D_wj = D_w(w_j, corpus)\n",
        "        # Joint document frequency\n",
        "        D_wi_wj = 0\n",
        "        for i in range(len(corpus)):\n",
        "          if (w_i in corpus[i]) and (w_j in corpus[i]):\n",
        "            D_wi_wj += 1\n",
        "\n",
        "        if D_wi_wj == 0:\n",
        "          f_wi_wj = -1\n",
        "        else:\n",
        "          f_wi_wj = -1 + (np.log(D_wi)+np.log(D_wj)-2.0*np.log(D)) / (np.log(D_wi_wj)-np.log(D))\n",
        "        tmp += f_wi_wj\n",
        "        counter += 1\n",
        "      \n",
        "      TC_k += tmp\n",
        "    \n",
        "    TC.append(TC_k)\n",
        "    TC = np.mean(TC) / counter\n",
        "\n",
        "    return TC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob7mCA6_adAu",
        "colab_type": "code",
        "outputId": "2e6c6607-889c-46de-b629-7a702f02a95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Topic Coherence(TC) for 20 topics\n",
        "topic_coherence_20 = topic_coherence(corpus=processed_docs, topics=topics_20)\n",
        "print(\"The Topic Coherence(TC) for 20 topics of LDA model calculated from scratch is:\", topic_coherence_20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) for 20 topics of LDA model calculated from scratch is: -0.0018815240063567594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b_TCPjJcotR",
        "colab_type": "code",
        "outputId": "8790d903-dee4-473e-8674-dab5be995793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Topic Coherence(TC) for 50 topics\n",
        "topic_coherence_50 = topic_coherence(corpus=processed_docs, topics=topics_50)\n",
        "print(\"The Topic Coherence(TC) for 50 topics of LDA model calculated from scratch is:\", topic_coherence_50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) for 50 topics of LDA model calculated from scratch is: 0.147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igFci-eb9DHh",
        "colab_type": "code",
        "outputId": "015bf662-57e8-4cd8-c766-423bfcbcf0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Topic Coherence(TC) for 100 topics\n",
        "topic_coherence_100 = topic_coherence(corpus=processed_docs, topics=topics_100)\n",
        "print(\"The Topic Coherence(TC) for 100 topics of LDA model calculated from scratch is:\", topic_coherence_100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) for 100 topics of LDA model calculated from scratch is: 0.142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icN9vs_s9Ewb",
        "colab_type": "code",
        "outputId": "68016eca-0158-401d-b55c-46357990de58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Topic Coherence(TC) for 50 topics\n",
        "topic_coherence_300 = topic_coherence(corpus=processed_docs, topics=topics_300)\n",
        "print(\"The Topic Coherence(TC) for 300 topics of LDA model calculated from scratch is:\", topic_coherence_300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Coherence(TC) for 300 topics of LDA model calculated from scratch is: 0.108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M6fAhTsic4p",
        "colab_type": "text"
      },
      "source": [
        "**2. Calculate Topic Diversity(TD)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXBVVo-_9re4",
        "colab_type": "text"
      },
      "source": [
        "This part I implemented the same calculation method of Topic Diversity(TD) with ETM, from TD perspect, LDA get better results compare to ETM on topic diversity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_6GF8LCat42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "# Filter out punctuations\n",
        "def contains_punctuation(w):\n",
        "    return any(char in string.punctuation for char in w)\n",
        "\n",
        "# Filter out numeric values\n",
        "def contains_numeric(w):\n",
        "    return any(char.isdigit() for char in w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spf_8u-c9Mek",
        "colab_type": "code",
        "outputId": "ad1a2cf1-103a-45c6-abe6-279c0dcc230f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "TD for 20 topics\n",
        "\"\"\"\n",
        "# Get all words in generated 20 topics \n",
        "topic_words_20 = []\n",
        "for i in range(len(topics_20)):\n",
        "  topic = topics_20[i]\n",
        "  topic = [w.lower() for w in topic if not contains_punctuation(w)] \n",
        "  topic = [w for w in topic if not contains_numeric(w)]\n",
        "  topic = \"\".join(topic)\n",
        "  topic = topic.split(sep=' ')\n",
        "  topic = [w for w in topic if w != '']\n",
        "  topic_words_20.extend(topic)\n",
        "\n",
        "# Get all unique words for 50 topics \n",
        "unique_words_20 = []\n",
        "for w in topic_words_20:\n",
        "  if w not in unique_words_20:\n",
        "    unique_words_20.append(w)\n",
        "\n",
        "# Calculate Topic Diversity(TD)\n",
        "TD_20 = len(unique_words_20) / len(topic_words_20)\n",
        "\n",
        "print(\"The Topic Diversity(TD) for 20 topics of LDA model is: \", TD_20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Diversity(TD) for 20 topics of LDA model is:  0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igH8HxXp91fC",
        "colab_type": "code",
        "outputId": "0542d974-b1c6-488f-c781-b985deb3f321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "TD for 50 topics\n",
        "\"\"\"\n",
        "# Get all words in generated 50 topics \n",
        "topic_words_50 = []\n",
        "for i in range(len(topics_50)):\n",
        "  topic = topics_50[i]\n",
        "  topic = [w.lower() for w in topic if not contains_punctuation(w)] \n",
        "  topic = [w for w in topic if not contains_numeric(w)]\n",
        "  topic = \"\".join(topic)\n",
        "  topic = topic.split(sep=' ')\n",
        "  topic = [w for w in topic if w != '']\n",
        "  topic_words_50.extend(topic)\n",
        "\n",
        "# Get all unique words for 50 topics \n",
        "unique_words_50 = []\n",
        "for w in topic_words_50:\n",
        "  if w not in unique_words_50:\n",
        "    unique_words_50.append(w)\n",
        "\n",
        "# Calculate Topic Diversity(TD)\n",
        "TD_50 = len(unique_words_50) / len(topic_words_50)\n",
        "\n",
        "print(\"The Topic Diversity(TD) for 50 topics of LDA model is: \", TD_50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Diversity(TD) for 50 topics of LDA model is:  0.947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6PL4Qt3-NZG",
        "colab_type": "code",
        "outputId": "7d48bfb0-e4fc-4a9d-ba46-b54dcd533126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "TD for 100 topics\n",
        "\"\"\"\n",
        "# Get all words in generated 50 topics \n",
        "topic_words_100 = []\n",
        "for i in range(len(topics_100)):\n",
        "  topic = topics_100[i]\n",
        "  topic = [w.lower() for w in topic if not contains_punctuation(w)] \n",
        "  topic = [w for w in topic if not contains_numeric(w)]\n",
        "  topic = \"\".join(topic)\n",
        "  topic = topic.split(sep=' ')\n",
        "  topic = [w for w in topic if w != '']\n",
        "  topic_words_100.extend(topic)\n",
        "\n",
        "# Get all unique words\n",
        "unique_words_100 = []\n",
        "for w in topic_words_100:\n",
        "  if w not in unique_words_100:\n",
        "    unique_words_100.append(w)\n",
        "\n",
        "# Calculate Topic Diversity(TD)\n",
        "TD_100 = len(unique_words_100) / len(topic_words_100)\n",
        "\n",
        "print(\"The Topic Diversity(TD) for 100 topics of LDA model is: \", TD_100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Diversity(TD) for 100 topics of LDA model is:  0.991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aVF0QDgulE9",
        "colab_type": "code",
        "outputId": "85e4f9b1-9c58-4ea6-e092-9f7453437606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "TD for 300 topics\n",
        "\"\"\"\n",
        "# Get all words in generated 50 topics \n",
        "topic_words_300 = []\n",
        "for i in range(len(topics_300)):\n",
        "  topic = topics_300[i]\n",
        "  topic = [w.lower() for w in topic if not contains_punctuation(w)] \n",
        "  topic = [w for w in topic if not contains_numeric(w)]\n",
        "  topic = \"\".join(topic)\n",
        "  topic = topic.split(sep=' ')\n",
        "  topic = [w for w in topic if w != '']\n",
        "  topic_words_300.extend(topic)\n",
        "\n",
        "# Get all unique words\n",
        "unique_words_300 = []\n",
        "for w in topic_words_300:\n",
        "  if w not in unique_words_300:\n",
        "    unique_words_300.append(w)\n",
        "\n",
        "# Calculate Topic Diversity(TD)\n",
        "TD_300 = len(unique_words_300) / len(topic_words_300)\n",
        "\n",
        "print(\"The Topic Diversity(TD) for 300 topics of LDA model is: \", TD_300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Topic Diversity(TD) for 300 topics of LDA model is:  0.996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2kKaiUmK8os",
        "colab_type": "text"
      },
      "source": [
        "### **Query On New Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_G63Gu5LGBN",
        "colab_type": "text"
      },
      "source": [
        "Query the model using test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFDLtujNRzQG",
        "colab_type": "code",
        "outputId": "f040bbb7-30fe-4594-d53b-0f7cae1655cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Word stemming and lemmatization\n",
        "def lemmatize_stemming(text):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Text preprocessing\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "\n",
        "    return result\n",
        "\n",
        "# Get preprocessed dataset\n",
        "test_docs = []\n",
        "for doc in newsgroups_test.data[0:100]:\n",
        "    test_docs.append(preprocess(doc))\n",
        "\n",
        "# Create word dictionary / word2id\n",
        "dictionary = gensim.corpora.Dictionary(test_docs)\n",
        "\n",
        "# Filter out low frequency and high frequency words\n",
        "dictionary.filter_extremes(no_below=10, no_above=0.7, keep_n=100000)\n",
        "\n",
        "# Create Bag of Words(BOW) representation of dataset\n",
        "bow_test = [dictionary.doc2bow(doc) for doc in test_docs]\n",
        "\n",
        "# Query on test docs\n",
        "vector = lda_model_20[bow_test[0]]\n",
        "print(\"Generated vectors are: \\n\", vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated vectors are: \n",
            " [(0, 0.07990225), (3, 0.13209473), (7, 0.3069345), (14, 0.17250848), (16, 0.26168504)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}